{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing the accuracy of the Harr feature-based cascade \n",
    "# classifier for face detection\n",
    "\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "    help=\"path to the input image\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# set paths of haar-feature based classifiers\n",
    "xml1 = 'Classifiers/4kdogcascade.xml'\n",
    "xml2 = 'Classifiers/4kcatcascade.xml'\n",
    "\n",
    "# load input image, resize it, convert it to grayscale, \n",
    "# and pass a 5x5 gaussian flter over it\n",
    "image = cv2.imread(args[\"image\"])\n",
    "imagef = cv2.resize(image, (150, image.shape[0]*150//image.shape[1]))\n",
    "grayf = cv2.cvtColor(imagef, cv2.COLOR_BGR2GRAY)\n",
    "grayf = cv2.blur(grayf,(5,5))\n",
    "\n",
    "# create cascade classifier objects\n",
    "detector1 = cv2.CascadeClassifier(xml1)\n",
    "detector2 = cv2.CascadeClassifier(xml2)\n",
    "\n",
    "# load detectors and store coordinates of detected regions\n",
    "rects1 = detector1.detectMultiScale(grayf, scaleFactor=1.3, minNeighbors=10, minSize=(20, 20))\n",
    "rects2 = detector2.detectMultiScale(grayf, scaleFactor=1.3, minNeighbors=10, minSize=(20, 20))\n",
    "\n",
    "rects = []\n",
    "if len(rects1)>0 and len(rects2)==0:\n",
    "    for i in range(0,len(rects1)):\n",
    "        rects.append(rects1[i])\n",
    "elif len(rects2)>0 and len(rects1)==0:\n",
    "    for i in range(0,len(rects2)):\n",
    "        rects.append(rects2[i])\n",
    "elif len(rects1)>0 and len(rects2)>0: \n",
    "    rects.append(rects1[0])\n",
    "    rects.append(rects2[0])\n",
    "\n",
    "# initialize lists of rectangle edge positions\n",
    "X = []\n",
    "Y = []\n",
    "XW = []\n",
    "YH = []\n",
    "\n",
    "# loop over the rectangles and record edge positions\n",
    "for (i, (x, y, w, h)) in enumerate(rects):\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    XW.append(x+w)\n",
    "    YH.append(y+h)\n",
    "\n",
    "# get minimum and maximum rectangle coordinates\n",
    "if len(X) != 0:\n",
    "    xMin = min(X)\n",
    "    yMin = min(Y)\n",
    "    xwMax = max(XW)\n",
    "    yhMax = max(YH)\n",
    "# if no region of image was detected, use the whole image\n",
    "else:\n",
    "    height,width = gray.shape\n",
    "    xMin,yMin,xwMax,yhMax = 0,0,width,height\n",
    "\n",
    "# draw large rectangle based on extreme coordinates of small rectangles\n",
    "cv2.rectangle(imagef, (xMin, yMin), (xwMax, yhMax), (0, 0, 255), 2)\n",
    "\n",
    "# display smaller rectangles\n",
    "for (i, (x, y, w, h)) in enumerate(rects):\n",
    "    cv2.rectangle(imagef, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# show the detected faces\n",
    "cv2.imshow(\"Animal Faces\", imagef)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# save image with face detection rectangle\n",
    "#cv2.imwrite('photo.jpg', imagef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM classifier training \n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# function for reading csv files to assign labels to training imges\n",
    "def csv_reader(file_obj):\n",
    "    labels = []\n",
    "    reader = csv.reader(file_obj)\n",
    "    for row in reader:\n",
    "        labels.append(row)\n",
    "    return labels\n",
    "\n",
    "# load haar-feature based classifiers\n",
    "xml1 = 'Classifiers/4kdogcascade.xml'\n",
    "xml2 = 'Classifiers/4kcatcascade.xml'\n",
    "\n",
    "# create cascade classifier objects\n",
    "detector1 = cv2.CascadeClassifier(xml1)\n",
    "detector2 = cv2.CascadeClassifier(xml2)\n",
    "\n",
    "# set path for image label csv file\n",
    "yPath = 'Y_Train.csv'\n",
    "\n",
    "# load image names and labels into array\n",
    "with open(yPath, \"r\") as file:\n",
    "    csv = csv_reader(file)\n",
    "\n",
    "# remove header line from csv file\n",
    "del csv[0]\n",
    "\n",
    "# set path for training image folder\n",
    "samplePath = 'C:/Users/Raymond/Desktop/trainSet'\n",
    "xPath = samplePath + '/'\n",
    "\n",
    "# generate list of images in training image folder\n",
    "filenames = []\n",
    "for root, dirs, files in os.walk(samplePath):\n",
    "    filenames = files \n",
    "\n",
    "# initialize array for storing LBP histogram of each image\n",
    "xData = np.zeros((len(filenames),256), dtype=np.float64)\n",
    "\n",
    "# initialize list for storing image labels\n",
    "yData = []\n",
    "\n",
    "# loop through all images in training folder\n",
    "for i in range(0,len(filenames)):\n",
    "    curr_path = xPath + filenames[i]\n",
    "\n",
    "    # load input image, resize it, convert it to grayscale, and pass a 5x5 gaussian flter over it\n",
    "    image = cv2.imread(curr_path)\n",
    "    image = cv2.resize(image, (150, image.shape[0]*150//image.shape[1]))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.blur(gray,(5,5))\n",
    "\n",
    "    # load detectors and store coordinates of detected regions\n",
    "    rects1 = detector1.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=10, minSize=(25, 25))\n",
    "    rects2 = detector2.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=10, minSize=(25, 25))\t\n",
    "\n",
    "    rects = []\n",
    "    if len(rects1)>0 and len(rects2)==0:\n",
    "        for i in range(0,len(rects1)):\n",
    "            rects.append(rects1[i])\n",
    "    elif len(rects2)>0 and len(rects1)==0:\n",
    "        for i in range(0,len(rects2)):\n",
    "            rects.append(rects2[i])\n",
    "    elif len(rects1)>0 and len(rects2)>0: \n",
    "        rects.append(rects1[0])\n",
    "        rects.append(rects2[0])\n",
    "\n",
    "    # initialize lists of rectangle edge positions\n",
    "    X = []\n",
    "    Y = []\n",
    "    XW = []\n",
    "    YH = []\n",
    "\n",
    "    # loop over the rectangles and record edge positions\n",
    "    for (i, (x, y, w, h)) in enumerate(rects):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        XW.append(x+w)\n",
    "        YH.append(y+h)\n",
    "\n",
    "    # get minimum and maximum rectangle coordinates\n",
    "    if len(X) != 0:\n",
    "        xMin = min(X)\n",
    "        yMin = min(Y)\n",
    "        xwMax = max(XW)\n",
    "        yhMax = max(YH)\n",
    "    # if no region of image was detected, use the whole image\n",
    "    else:\n",
    "        height,width = gray.shape\n",
    "        xMin,yMin,xwMax,yhMax = 0,0,width,height\n",
    "    \n",
    "    # make one large rectangle by using extreme coordinates of smaller rectangles\n",
    "    # and use that region to compute LBP and the LBP's normalized histogram \n",
    "    cropped_img = gray[yMin:yhMax,xMin:xwMax]\n",
    "    lbp = local_binary_pattern(cropped_img, 8, 1, \"default\")\n",
    "    hist, _ = np.histogram(lbp, 256, density=True)\n",
    "\n",
    "    # save histogram into xData array\n",
    "    xData[i] = hist\n",
    "\n",
    "    # obtain image label using the current image's name\n",
    "    img_index = int(filenames[i][:-4])\n",
    "    yData.append(csv[img_index][1])\n",
    "\n",
    "# create linear SVM object \n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "# fit data \n",
    "clf.fit(xData,yData)\n",
    "\n",
    "# save training model in .pkl format\n",
    "joblib.dump(clf, 'training_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM prediction, generates csv file with image names and predicted labels\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "import csv\n",
    "\n",
    "# function for writing csv files\n",
    "def csv_writer(data, path):\n",
    "    with open(path, \"w\", newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        for line in data:\n",
    "            writer.writerow(line)\n",
    "\n",
    "# load haar-feature based classifiers\n",
    "xml1 = 'Classifiers/4kdogcascade.xml'\n",
    "xml2 = 'Classifiers/4kcatcascade.xml'\n",
    "\n",
    "# create cascade classifier objects\n",
    "detector1 = cv2.CascadeClassifier(xml1)\n",
    "detector2 = cv2.CascadeClassifier(xml2)\n",
    "\n",
    "# load training model\n",
    "clf = joblib.load('Training_Models/training_model.pkl')\n",
    "\n",
    "# set path for output csv file\n",
    "outputpath = 'predictions.csv'\n",
    "\n",
    "# generate list of files from test image folder\n",
    "filenames = []\n",
    "for root, dirs, files in os.walk('C:/Users/Raymond/Desktop/X_Test'):\n",
    "    filenames = files \n",
    "testpath = 'C:/Users/Raymond/Desktop/X_Test/'\n",
    "\n",
    "# initialize array to store LBP histograms\n",
    "xSamples = np.zeros((len(filenames),256), dtype=np.float64)\n",
    "\n",
    "# initialize list for storing image names and predictied labels\n",
    "outputlist = []\n",
    "outputlist.append(\"Image,Label\".split(\",\"))\n",
    "\n",
    "# loop through all images in test image folder\n",
    "for i in range(0,len(filenames)):\n",
    "    # load input image, resize it, convert it to grayscale, and pass a 5x5 gaussian flter over it\n",
    "    image = cv2.imread(testpath + filenames[i])\n",
    "    image = cv2.resize(image, (150, image.shape[0]*150//image.shape[1]))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.blur(gray,(5,5))\n",
    "\n",
    "    # load detectors and store coordinates of detected regions\n",
    "    rects1 = detector1.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=10, minSize=(25, 25))\n",
    "    rects2 = detector2.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=10, minSize=(25, 25))\t\t\t\n",
    "\n",
    "    rects = []\n",
    "    if len(rects1)>0 and len(rects2)==0:\n",
    "        for i in range(0,len(rects1)):\n",
    "            rects.append(rects1[i])\n",
    "    elif len(rects2)>0 and len(rects1)==0:\n",
    "        for i in range(0,len(rects2)):\n",
    "            rects.append(rects2[i])\n",
    "    elif len(rects1)>0 and len(rects2)>0: \n",
    "        rects.append(rects1[0])\n",
    "        rects.append(rects2[0])\n",
    "\n",
    "    # initialize lists of rectangle edge positions\n",
    "    X = []\n",
    "    Y = []\n",
    "    XW = []\n",
    "    YH = []\n",
    "\n",
    "    # loop over the rectangles and record edge positions\n",
    "    for (i, (x, y, w, h)) in enumerate(rects):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        XW.append(x+w)\n",
    "        YH.append(y+h)\n",
    "\n",
    "    # get minimum and maximum rectangle coordinates\n",
    "    if len(X) != 0:\n",
    "        xMin = min(X)\n",
    "        yMin = min(Y)\n",
    "        xwMax = max(XW)\n",
    "        yhMax = max(YH)\n",
    "    # if no region of image was detected, use the whole image\n",
    "    else:\n",
    "        height,width = gray.shape\n",
    "        xMin,yMin,xwMax,yhMax = 0,0,width,height\n",
    "    \n",
    "    # make one large rectangle by using extreme coordinates of smaller rectangles\n",
    "    # and use that region to compute LBP and the LBP's normalize \n",
    "    cropped_img = gray[yMin:yhMax,xMin:xwMax]\n",
    "    lbp = local_binary_pattern(cropped_img, 8, 1, \"default\")\n",
    "    hist, _ = np.histogram(lbp, 256, density=True)\n",
    "\n",
    "    # save histogram into xSamples array\n",
    "    xSamples[i] = hist\n",
    "\n",
    "# predict labels using LBP histograms\n",
    "predictions = clf.predict(xSamples)\n",
    "\n",
    "# put image names and labels into list\n",
    "for i in range(0,len(filenames)):\n",
    "    outputlist.append((filenames[i]+\",\"+predictions[i]).split(\",\"))\n",
    "\n",
    "# write output data into csv file\n",
    "csv_writer(outputlist,outputpath)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
